{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download data with the following commands in shell:\n",
    "```\n",
    "wget http://mattmahoney.net/dc/text8.zip -O text8.zip\n",
    "unzip text8.zip\n",
    "wget https://storage.googleapis.com/google-code-archive-source/v2/code.google.com/word2vec/source-archive.zip\n",
    "unzip -p source-archive.zip  word2vec/trunk/questions-words.txt > questions-words.txt\n",
    "rm source-archive.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import tensorflow as tf\n",
    "from word2vec import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reload(logging)\n",
    "logging_filename = \"training.log\"\n",
    "logging.basicConfig(format = \"[%(asctime)s] %(message)s\",\n",
    "                    datefmt = \"%Y-%m-%d %H:%M:%S\",\n",
    "                    level = logging.INFO,\n",
    "                    filename = logging_filename)\n",
    "\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data file: text8\n",
      "Vocabulary size: 71290 + UNK\n",
      "Most frequent words: [[('UNK', 286363), ('the', 1061396), ('of', 593677), ('and', 416629), ('one', 411764), ('in', 372201), ('a', 325873), ('to', 316376), ('zero', 264975), ('nine', 250430)]]\n",
      "Analogy questions used: 17827 skipped: 1717\n"
     ]
    }
   ],
   "source": [
    "# Create a model.\n",
    "training_data_filename = \"text8\"\n",
    "training_results_path = \"training-results\"\n",
    "analogy_questions_filename = \"questions-words.txt\"\n",
    "epochs_to_train = 30\n",
    "model = Word2Vec(sess, \n",
    "                 for_training = True,\n",
    "                 training_data_filename = training_data_filename,\n",
    "                 training_results_path = training_results_path,\n",
    "                 analogy_questions_filename = analogy_questions_filename,\n",
    "                 epochs_to_train = epochs_to_train)\n",
    "\n",
    "# Print some statistics.\n",
    "print \"Training data file:\", training_data_filename\n",
    "print \"Vocabulary size:\", len(model.words) - 1, \"+ UNK\"\n",
    "print \"Most frequent words:\", [zip(model.words, model.word_freq)[:10]]\n",
    "print \"Analogy questions used:\", len(model.analogy_questions), \"skipped:\", model.num_analogy_questions_skipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for epoch in xrange(epochs_to_train):\n",
    "    model.train()\n",
    "    logging.info(\"Epoch %d, Analogy accuracy: %f\", epoch+1, model.evaluate_analogy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
