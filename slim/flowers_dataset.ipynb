{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download raw photos:\n",
    "```\n",
    "cd ~/data/flowers\n",
    "wget http://download.tensorflow.org/example_images/flower_photos.tgz\n",
    "tar -xzvf flower_photos.tgz\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import logging\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path\n",
    "import PIL\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "\n",
    "from xy_python_utils.os_utils import mkdir_p\n",
    "\n",
    "from flowers_dataset import (\n",
    "    get_dataset,\n",
    "    write_label_file,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reload(logging)\n",
    "logging.basicConfig(format = \"[%(asctime)s] %(message)s\",\n",
    "                    datefmt = \"%Y-%m-%d %H:%M:%S\",\n",
    "                    level = logging.INFO)\n",
    "\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "home_dir = os.path.expanduser('~')\n",
    "base_dir = os.path.join(home_dir, \"data/flowers\")\n",
    "photos_dir = os.path.join(base_dir, \"flower_photos\")\n",
    "tf_records_dir = os.path.join(base_dir, \"tfrecords\")\n",
    "mkdir_p(tf_records_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_filenames_and_classes(photos_dir):\n",
    "    directories = []\n",
    "    class_names = []\n",
    "    for filename in os.listdir(photos_dir):\n",
    "        path = os.path.join(photos_dir, filename)\n",
    "        if os.path.isdir(path):\n",
    "            directories.append(path)\n",
    "            class_names.append(filename)\n",
    "\n",
    "    photo_filenames = []\n",
    "    for directory in directories:\n",
    "        for filename in os.listdir(directory):\n",
    "            path = os.path.join(directory, filename)\n",
    "            photo_filenames.append(path)\n",
    "            \n",
    "    return photo_filenames, class_names\n",
    "\n",
    "\n",
    "photo_filenames, class_names = get_filenames_and_classes(photos_dir)\n",
    "write_label_file(class_names, os.path.join(tf_records_dir, \"labels.txt\"))\n",
    "class_name_to_id = {v: k for k, v in enumerate(class_names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split data into training and validation set.\n",
    "random_seed = 0\n",
    "num_validation = 350\n",
    "random.seed(random_seed)\n",
    "random.shuffle(photo_filenames)\n",
    "validation_filenames = photo_filenames[:num_validation]\n",
    "training_filenames = photo_filenames[num_validation:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-09 21:37:24] Processing train, shard 0 out of 5\n",
      "[2016-11-09 21:37:25] Processing train, shard 1 out of 5\n",
      "[2016-11-09 21:37:26] Processing train, shard 2 out of 5\n",
      "[2016-11-09 21:37:28] Processing train, shard 3 out of 5\n",
      "[2016-11-09 21:37:28] Processing train, shard 4 out of 5\n",
      "[2016-11-09 21:37:29] Processing validation, shard 0 out of 5\n",
      "[2016-11-09 21:37:32] Processing validation, shard 1 out of 5\n",
      "[2016-11-09 21:37:34] Processing validation, shard 2 out of 5\n",
      "[2016-11-09 21:37:36] Processing validation, shard 3 out of 5\n",
      "[2016-11-09 21:37:38] Processing validation, shard 4 out of 5\n"
     ]
    }
   ],
   "source": [
    "def get_dataset_filename(dataset_dir, split_name, shard_id, num_shards):\n",
    "    output_filename = \"flowers_%s_%05d-of-%05d.tfrecord\" % (split_name, shard_id, num_shards)\n",
    "    return os.path.join(dataset_dir, output_filename)\n",
    "\n",
    "\n",
    "def bytes_feature(values):\n",
    "    return tf.train.Feature(bytes_list = tf.train.BytesList(value=[values]))\n",
    "\n",
    "\n",
    "def int64_feature(values):\n",
    "    return tf.train.Feature(int64_list = tf.train.Int64List(value=[values]))\n",
    "\n",
    "\n",
    "def image_to_tfexample(image_data, image_format, class_id):\n",
    "    return tf.train.Example(features = tf.train.Features(feature = {\n",
    "                \"image/encoded\": bytes_feature(image_data),\n",
    "                \"image/format\": bytes_feature(image_format),\n",
    "                \"image/class/label\": int64_feature(class_id),\n",
    "            }))\n",
    "\n",
    "\n",
    "def convert_dataset(split_name, filenames, class_names_to_id, dataset_dir, num_shards = 5):\n",
    "    assert split_name in (\"train\", \"validation\")\n",
    "    num_per_shard = int(math.ceil(len(filenames) / num_shards))\n",
    "    for shard_id in xrange(num_shards):\n",
    "        logging.info(\"Processing %s, shard %d out of %d\", split_name, shard_id, num_shards)\n",
    "        output_filename = get_dataset_filename(dataset_dir, split_name, shard_id, num_shards)\n",
    "        with tf.python_io.TFRecordWriter(output_filename) as tfrecord_writer:\n",
    "            start_idx = shard_id * num_per_shard\n",
    "            end_idx = min((shard_id+1) * num_per_shard, len(filenames))\n",
    "            for idx in xrange(start_idx, end_idx):\n",
    "                # Read the image data.\n",
    "                image_data = tf.gfile.FastGFile(filenames[idx], 'r').read()\n",
    "                # Read class name from folder path.\n",
    "                class_name = os.path.basename(os.path.dirname(filenames[idx]))\n",
    "                class_id = class_names_to_id[class_name]\n",
    "                # Create an example and serialize to disk.\n",
    "                example = image_to_tfexample(image_data, \"jpg\", class_id)\n",
    "                tfrecord_writer.write(example.SerializeToString())\n",
    "\n",
    "\n",
    "convert_dataset(\"train\", training_filenames, class_name_to_id, tf_records_dir)\n",
    "convert_dataset(\"validation\", validation_filenames, class_name_to_id, tf_records_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = get_dataset(\"train\", tf_records_dir)\n",
    "data_provider = slim.dataset_data_provider.DatasetDataProvider(dataset, common_queue_capacity=32, common_queue_min=1)\n",
    "image, label = data_provider.get([\"image\", \"label\"])\n",
    "with slim.queues.QueueRunners(sess):\n",
    "    np_image, np_label = sess.run([image, label])\n",
    "    height, width, _ = np_image.shape\n",
    "    class_name = dataset.labels_to_names[np_label]\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.imshow(np_image)\n",
    "    plt.title(\"%s, %d x %d\" % (class_name, height, width))\n",
    "    plt.axis(\"off\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
